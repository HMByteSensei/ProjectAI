{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "7IrWl0sHEE2D",
        "outputId": "10bf3035-c178-43ec-92c3-5a2a48563619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1CPdZPpT6rBKZx83VxCsG9kgJumpVOf3F\n",
            "From (redirected): https://drive.google.com/uc?id=1CPdZPpT6rBKZx83VxCsG9kgJumpVOf3F&confirm=t&uuid=d6471e2c-4bca-4a08-8155-1a32a4b92942\n",
            "To: /content/[F2]sumarizovani_tekstovi (1).zip\n",
            "100%|██████████| 485M/485M [00:06<00:00, 69.9MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[F2]sumarizovani_tekstovi (1).zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!pip install --upgrade gdown\n",
        "import gdown\n",
        "\n",
        "# https://drive.google.com/file/d/1CPdZPpT6rBKZx83VxCsG9kgJumpVOf3F/view?usp=drive_link\n",
        "file_id = \"1CPdZPpT6rBKZx83VxCsG9kgJumpVOf3F\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"[F2]sumarizovani_tekstovi (1).zip\", quiet=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"[F2]sumarizovani_tekstovi (1).zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"[F2]sumarizovani_tekstovi\")"
      ],
      "metadata": {
        "id": "-rFeNos7EpQG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import nltk; nltk.download('punkt')\"\n",
        "!pip install sumy transformers datasets torch pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_1JSXHfExhQ",
        "outputId": "c316dac4-d105-4d97-a8a7-63a197850e7d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Collecting sumy\n",
            "  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting docopt<0.7,>=0.6.1 (from sumy)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting breadability>=0.1.20 (from sumy)\n",
            "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from sumy) (2.32.3)\n",
            "Collecting pycountry>=18.2.23 (from sumy)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from sumy) (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.4.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: breadability, docopt\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21693 sha256=3d57464a0c32f8d84795b68d04f3e8e4cc10f3ee1b7c5e7c63fe91c2ecbf5a6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/57/58/7e3d7fedf51fe248b7fcee3df6945ae28638e22cddf01eb92b\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=942a595345b667b951331cb58143a2b23330837751792c49f4d068477ab09c30\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "Successfully built breadability docopt\n",
            "Installing collected packages: docopt, xxhash, pycountry, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, breadability, sumy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed breadability-0.1.20 datasets-3.6.0 dill-0.3.8 docopt-0.6.2 fsspec-2025.3.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pycountry-24.6.1 sumy-0.11.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "# Faza 3: Izračunavanje evaluacijskih metrika (Compression, Coverage, Density)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "\n",
        "# Povezivanje Google Drive-a\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Bosanske stop riječi - koristićemo za izračunavanje gustoće (density)\n",
        "STOP_RIJECI = [\n",
        "    'i', 'u', 'je', 'da', 'se', 'na', 'su', 'za', 'od', 'što', 'kako', 'ali', 'a', 'ili',\n",
        "    'to', 'nije', 'sam', 'mi', 'ti', 'on', 'ona', 'ono', 'oni', 'one', 'smo', 'ste', 'sa',\n",
        "    'jer', 'po', 'kad', 'kao', 'do', 'iz', 'bi', 'te', 'tako', 'pri', 'nakon', 'već', 'o',\n",
        "    'kroz', 'još', 'samo', 'sve', 'ako', 'mogu', 'može', 'biti', 'bio', 'bila', 'bilo',\n",
        "    'bili', 'bile', 'će', 'ću', 'ćemo', 'ćete', 'neće', 'ne', 'niti', 'pa', 'dok',\n",
        "    'prije', 'ovaj', 'ova', 'ovo', 'ovi', 'ove', 'taj', 'ta', 'to', 'ti', 'te', 'svoj',\n",
        "    'svoja', 'svoje', 'svoji', 'svoje', 'moj', 'moja', 'moje', 'moji', 'moje'\n",
        "]\n",
        "\n",
        "# Funkcija za pronalaženje ispravne putanje\n",
        "def find_correct_path(folder_name):\n",
        "    print(f\"Tražim ispravnu putanju za {folder_name}...\")\n",
        "\n",
        "    # Provjerite nekoliko mogućih lokacija\n",
        "    potential_paths = [\n",
        "        f'/content/drive/MyDrive/{folder_name}',\n",
        "        f'/content/drive/My Drive/{folder_name}',\n",
        "        f'/content/drive/Shared drives/{folder_name}'\n",
        "    ]\n",
        "\n",
        "    # Provjera svih putanja\n",
        "    for path in potential_paths:\n",
        "        print(f\"Provjeravam: {path}\")\n",
        "        if os.path.exists(path):\n",
        "            print(f\"Pronađena putanja: {path}\")\n",
        "            return path\n",
        "\n",
        "    # Ako ne možemo naći tačnu lokaciju, tražimo unos od korisnika\n",
        "    print(\"\\nNe mogu pronaći folder. Evo sadržaja vašeg drive-a:\")\n",
        "    root_contents = os.listdir('/content/drive')\n",
        "    print(f\"Root sadržaj: {root_contents}\")\n",
        "\n",
        "    if 'MyDrive' in root_contents or 'My Drive' in root_contents:\n",
        "        mydrive_path = '/content/drive/MyDrive' if 'MyDrive' in root_contents else '/content/drive/My Drive'\n",
        "        print(f\"\\nSadržaj vašeg MyDrive-a:\")\n",
        "        try:\n",
        "            mydrive_contents = os.listdir(mydrive_path)\n",
        "            for item in mydrive_contents:\n",
        "                print(f\"  - {item}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Ne mogu pristupiti: {e}\")\n",
        "\n",
        "    # Tražimo unos od korisnika\n",
        "    user_path = input(f\"\\nUnesite tačnu putanju do vašeg {folder_name} foldera (kopirajte putanju): \")\n",
        "    if os.path.exists(user_path):\n",
        "        return user_path\n",
        "    else:\n",
        "        print(f\"Putanja {user_path} ne postoji. Koristiću standardnu putanju.\")\n",
        "        return f'/content/drive/MyDrive/{folder_name}'\n",
        "\n",
        "# Funkcija za podjelu teksta na riječi (za izračunavanje metrika)\n",
        "def podijeli_na_rijeci(text):\n",
        "    # Prevođenje u mala slova i uklanjanje interpunkcije\n",
        "    text = text.lower()\n",
        "    words = re.findall(r'\\b\\w+\\b', text)\n",
        "    return words\n",
        "\n",
        "# Funkcija za izračunavanje metrika\n",
        "def izracunaj_metrike(originalni_tekst, sazetak):\n",
        "    if not originalni_tekst or not sazetak:\n",
        "        return {\n",
        "            \"Compression\": 0,\n",
        "            \"Coverage\": 0,\n",
        "            \"Density\": 0,\n",
        "            \"Compression_bin\": \"none\",\n",
        "            \"Coverage_bin\": \"none\",\n",
        "            \"Density_bin\": \"none\"\n",
        "        }\n",
        "\n",
        "    # Dobijanje riječi (bez stop riječi za gustoću)\n",
        "    orig_rijeci = podijeli_na_rijeci(originalni_tekst)\n",
        "    sazetak_rijeci = podijeli_na_rijeci(sazetak)\n",
        "\n",
        "    # Izračunavanje riječi bez stop-riječi (za gustoću)\n",
        "    orig_rijeci_bez_stop = [w for w in orig_rijeci if w not in STOP_RIJECI and len(w) > 2]\n",
        "    sazetak_rijeci_bez_stop = [w for w in sazetak_rijeci if w not in STOP_RIJECI and len(w) > 2]\n",
        "\n",
        "    # Brojanje jedinstvenih riječi bez stop-riječi\n",
        "    orig_unique = set(orig_rijeci_bez_stop)\n",
        "    sazetak_unique = set(sazetak_rijeci_bez_stop)\n",
        "\n",
        "    # Metrike\n",
        "    # 1. Compression: odnos dužine sažetka prema dužini originalnog teksta\n",
        "    compression = (len(sazetak_rijeci) / len(orig_rijeci)) * 100 if len(orig_rijeci) > 0 else 0\n",
        "\n",
        "    # 2. Coverage: procenat važnih riječi originalnog teksta koje su u sažetku\n",
        "    coverage = len(sazetak_unique.intersection(orig_unique)) / len(orig_unique) if len(orig_unique) > 0 else 0\n",
        "\n",
        "    # 3. Density: odnos važnih riječi prema ukupnoj dužini sažetka\n",
        "    density = (len(sazetak_unique) / len(sazetak_rijeci)) * 100 if len(sazetak_rijeci) > 0 else 0\n",
        "\n",
        "    # Određivanje kategorija (biniranje)\n",
        "    compression_bin = \"low\" if compression < 20 else (\"medium\" if compression < 50 else \"high\")\n",
        "    coverage_bin = \"low\" if coverage < 0.3 else (\"medium\" if coverage < 0.7 else \"high\")\n",
        "    density_bin = \"abstractive\" if density < 25 else (\"mixed\" if density < 35 else \"extractive\")\n",
        "\n",
        "    return {\n",
        "        \"Compression\": round(compression, 10),\n",
        "        \"Coverage\": round(coverage, 10),\n",
        "        \"Density\": round(density, 10),\n",
        "        \"Compression_bin\": compression_bin,\n",
        "        \"Coverage_bin\": coverage_bin,\n",
        "        \"Density_bin\": density_bin\n",
        "    }\n",
        "\n",
        "# Funkcija za procesiranje JSON fajla\n",
        "def procesiraj_json_metrike(ulazni_fajl, izlazni_fajl):\n",
        "    try:\n",
        "        # Učitavanje JSON\n",
        "        with open(ulazni_fajl, 'r', encoding='utf-8') as f:\n",
        "            podaci = json.load(f)\n",
        "\n",
        "        # Provjera da li je podaci lista (array) ili pojedinačni objekt\n",
        "        if isinstance(podaci, list):\n",
        "            # Ako je lista, procesiramo svaki objekt u listi\n",
        "            for item in podaci:\n",
        "                if 'Text' in item and ('ExtractiveSum' in item or 'AbstractiveSum' in item):\n",
        "                    # Izračunavanje metrika za ekstraktivnu sumarizaciju\n",
        "                    if 'ExtractiveSum' in item and item['ExtractiveSum']:\n",
        "                        metrike_eks = izracunaj_metrike(item['Text'], item['ExtractiveSum'])\n",
        "                        # Dodavanje prefiksa 'Extractive_' metrikama\n",
        "                        for key, value in metrike_eks.items():\n",
        "                            item[f'Extractive_{key}'] = value\n",
        "\n",
        "                    # Izračunavanje metrika za abstraktivnu sumarizaciju\n",
        "                    if 'AbstractiveSum' in item and item['AbstractiveSum']:\n",
        "                        metrike_abs = izracunaj_metrike(item['Text'], item['AbstractiveSum'])\n",
        "                        # Dodavanje prefiksa 'Abstractive_' metrikama\n",
        "                        for key, value in metrike_abs.items():\n",
        "                            item[f'Abstractive_{key}'] = value\n",
        "        else:\n",
        "            # Pojedinačni objekat\n",
        "            if 'Text' in podaci:\n",
        "                # Izračunavanje metrika za ekstraktivnu sumarizaciju\n",
        "                if 'ExtractiveSum' in podaci and podaci['ExtractiveSum']:\n",
        "                    metrike_eks = izracunaj_metrike(podaci['Text'], podaci['ExtractiveSum'])\n",
        "                    # Dodavanje prefiksa 'Extractive_' metrikama\n",
        "                    for key, value in metrike_eks.items():\n",
        "                        podaci[f'Extractive_{key}'] = value\n",
        "\n",
        "                # Izračunavanje metrika za abstraktivnu sumarizaciju\n",
        "                if 'AbstractiveSum' in podaci and podaci['AbstractiveSum']:\n",
        "                    metrike_abs = izracunaj_metrike(podaci['Text'], podaci['AbstractiveSum'])\n",
        "                    # Dodavanje prefiksa 'Abstractive_' metrikama\n",
        "                    for key, value in metrike_abs.items():\n",
        "                        podaci[f'Abstractive_{key}'] = value\n",
        "\n",
        "        # Zapis novog JSON-a\n",
        "        os.makedirs(os.path.dirname(izlazni_fajl), exist_ok=True)\n",
        "        with open(izlazni_fajl, 'w', encoding='utf-8') as f:\n",
        "            json.dump(podaci, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Greška pri obradi JSON fajla {ulazni_fajl}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Funkcija za procesiranje CSV fajla\n",
        "def procesiraj_csv_metrike(ulazni_fajl, izlazni_fajl):\n",
        "    try:\n",
        "        # Čitanje CSV-a u pandas DataFrame\n",
        "        df = pd.read_csv(ulazni_fajl, encoding='utf-8')\n",
        "\n",
        "        # Provjera da li postoje potrebne kolone\n",
        "        if 'Text' in df.columns:\n",
        "            # Izračunavanje metrika za ekstraktivnu sumarizaciju\n",
        "            if 'ExtractiveSum' in df.columns:\n",
        "                metrike_df = df.apply(lambda row: izracunaj_metrike(row['Text'], row['ExtractiveSum'])\n",
        "                                     if pd.notna(row['Text']) and pd.notna(row['ExtractiveSum'])\n",
        "                                     else {\"Compression\": 0, \"Coverage\": 0, \"Density\": 0,\n",
        "                                           \"Compression_bin\": \"none\", \"Coverage_bin\": \"none\", \"Density_bin\": \"none\"},\n",
        "                                     axis=1)\n",
        "\n",
        "                # Dodavanje kolona sa ekstraktivnim metrikama\n",
        "                for key in [\"Compression\", \"Coverage\", \"Density\", \"Compression_bin\", \"Coverage_bin\", \"Density_bin\"]:\n",
        "                    df[f'Extractive_{key}'] = metrike_df.apply(lambda x: x[key])\n",
        "\n",
        "            # Izračunavanje metrika za abstraktivnu sumarizaciju\n",
        "            if 'AbstractiveSum' in df.columns:\n",
        "                metrike_df = df.apply(lambda row: izracunaj_metrike(row['Text'], row['AbstractiveSum'])\n",
        "                                     if pd.notna(row['Text']) and pd.notna(row['AbstractiveSum'])\n",
        "                                     else {\"Compression\": 0, \"Coverage\": 0, \"Density\": 0,\n",
        "                                           \"Compression_bin\": \"none\", \"Coverage_bin\": \"none\", \"Density_bin\": \"none\"},\n",
        "                                     axis=1)\n",
        "\n",
        "                # Dodavanje kolona sa abstraktivnim metrikama\n",
        "                for key in [\"Compression\", \"Coverage\", \"Density\", \"Compression_bin\", \"Coverage_bin\", \"Density_bin\"]:\n",
        "                    df[f'Abstractive_{key}'] = metrike_df.apply(lambda x: x[key])\n",
        "\n",
        "        # Zapis novog CSV-a\n",
        "        os.makedirs(os.path.dirname(izlazni_fajl), exist_ok=True)\n",
        "        df.to_csv(izlazni_fajl, index=False, encoding='utf-8')\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Greška pri obradi CSV fajla {ulazni_fajl}: {e}\")\n",
        "\n",
        "        try:\n",
        "            # Alternativni pristup ako pandas ne radi\n",
        "            print(\"Pokušavam alternativni pristup za obradu CSV fajla...\")\n",
        "            redovi = []\n",
        "            zaglavlja = []\n",
        "\n",
        "            # Čitanje CSV-a ručno\n",
        "            with open(ulazni_fajl, 'r', encoding='utf-8') as f:\n",
        "                reader = csv.reader(f)\n",
        "                zaglavlja = next(reader)  # Prva linija su zaglavlja\n",
        "\n",
        "                # Dodavanje novih polja za metrike\n",
        "                for prefix in ['Extractive_', 'Abstractive_']:\n",
        "                    for metriku in [\"Compression\", \"Coverage\", \"Density\", \"Compression_bin\", \"Coverage_bin\", \"Density_bin\"]:\n",
        "                        nova_kolona = f\"{prefix}{metriku}\"\n",
        "                        if nova_kolona not in zaglavlja:\n",
        "                            zaglavlja.append(nova_kolona)\n",
        "\n",
        "                # Indeksi potrebnih kolona\n",
        "                try:\n",
        "                    tekst_indeks = zaglavlja.index('Text')\n",
        "                    eks_indeks = zaglavlja.index('ExtractiveSum') if 'ExtractiveSum' in zaglavlja else -1\n",
        "                    abs_indeks = zaglavlja.index('AbstractiveSum') if 'AbstractiveSum' in zaglavlja else -1\n",
        "                except ValueError:\n",
        "                    print(\"CSV fajl ne sadrži potrebne kolone.\")\n",
        "                    return False\n",
        "\n",
        "                # Obrada redova\n",
        "                for red in reader:\n",
        "                    # Ako nemamo dovoljno kolona, proširimo red\n",
        "                    while len(red) < len(zaglavlja) - 12:  # -12 za nove kolone (6 za svaki tip sumarizacije)\n",
        "                        red.append(\"\")\n",
        "\n",
        "                    # Izračunavanje metrika ako imamo tekst i sažetke\n",
        "                    if tekst_indeks >= 0 and tekst_indeks < len(red) and red[tekst_indeks]:\n",
        "                        tekst = red[tekst_indeks]\n",
        "\n",
        "                        # Ekstraktivna sumarizacija\n",
        "                        if eks_indeks >= 0 and eks_indeks < len(red) and red[eks_indeks]:\n",
        "                            metrike_eks = izracunaj_metrike(tekst, red[eks_indeks])\n",
        "                            for key, value in metrike_eks.items():\n",
        "                                red.append(str(value))\n",
        "                        else:\n",
        "                            # Dodajemo prazne vrijednosti za metrike\n",
        "                            for _ in range(6):\n",
        "                                red.append(\"\")\n",
        "\n",
        "                        # Abstraktivna sumarizacija\n",
        "                        if abs_indeks >= 0 and abs_indeks < len(red) and red[abs_indeks]:\n",
        "                            metrike_abs = izracunaj_metrike(tekst, red[abs_indeks])\n",
        "                            for key, value in metrike_abs.items():\n",
        "                                red.append(str(value))\n",
        "                        else:\n",
        "                            # Dodajemo prazne vrijednosti za metrike\n",
        "                            for _ in range(6):\n",
        "                                red.append(\"\")\n",
        "                    else:\n",
        "                        # Dodajemo prazne vrijednosti za sve metrike\n",
        "                        for _ in range(12):\n",
        "                            red.append(\"\")\n",
        "\n",
        "                    redovi.append(red)\n",
        "\n",
        "            # Zapis novog CSV-a\n",
        "            os.makedirs(os.path.dirname(izlazni_fajl), exist_ok=True)\n",
        "            with open(izlazni_fajl, 'w', encoding='utf-8', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow(zaglavlja)\n",
        "                writer.writerows(redovi)\n",
        "\n",
        "            return True\n",
        "        except Exception as e2:\n",
        "            print(f\"Greška pri alternativnom pristupu za CSV: {e2}\")\n",
        "            return False\n",
        "\n",
        "# Funkcija za obradu svih fajlova\n",
        "def obradi_sve_fajlove(ulazni_folder, izlazni_folder):\n",
        "    # Pronađimo podfolder buka.ba\n",
        "    buka_folder = os.path.join(ulazni_folder, \"buka.ba\")\n",
        "\n",
        "    if not os.path.exists(buka_folder):\n",
        "        print(f\"GREŠKA: Folder {buka_folder} ne postoji!\")\n",
        "\n",
        "        # Pokušajmo pronaći tačnu strukturu\n",
        "        print(\"Tražim buka.ba folder...\")\n",
        "\n",
        "        # Ispisujemo sadržaj ulaznog foldera za dijagnostiku\n",
        "        print(f\"Sadržaj {ulazni_folder}:\")\n",
        "        try:\n",
        "            for item in os.listdir(ulazni_folder):\n",
        "                print(f\"  - {item}\")\n",
        "                item_path = os.path.join(ulazni_folder, item)\n",
        "                if os.path.isdir(item_path):\n",
        "                    print(f\"    Podfolderi u {item}:\")\n",
        "                    try:\n",
        "                        for subitem in os.listdir(item_path):\n",
        "                            print(f\"      - {subitem}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"      Greška pri čitanju: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Greška pri čitanju direktorija: {e}\")\n",
        "\n",
        "        # Tražimo alternativne putanje\n",
        "        alternative = [\n",
        "            os.path.join(ulazni_folder, \"buka_ba\"),\n",
        "            ulazni_folder  # Možda je glavni folder već buka.ba?\n",
        "        ]\n",
        "\n",
        "        for alt_path in alternative:\n",
        "            if os.path.exists(alt_path):\n",
        "                print(f\"Pronađena alternativna putanja: {alt_path}\")\n",
        "                buka_folder = alt_path\n",
        "                break\n",
        "\n",
        "    # Kreirajmo izlazni folder\n",
        "    izlazni_buka_folder = os.path.join(izlazni_folder, \"buka.ba\")\n",
        "    os.makedirs(izlazni_buka_folder, exist_ok=True)\n",
        "\n",
        "    processed_files = 0\n",
        "    errors = 0\n",
        "\n",
        "    # Prolazak kroz podfoldere\n",
        "    print(f\"Obrađujem fajlove iz {buka_folder}...\")\n",
        "\n",
        "    try:\n",
        "        for item in os.listdir(buka_folder):\n",
        "            item_path = os.path.join(buka_folder, item)\n",
        "\n",
        "            if os.path.isdir(item_path):\n",
        "                print(f\"Obrada direktorija: {item}\")\n",
        "\n",
        "                # Kreiranje odgovarajućeg izlaznog podfoldera\n",
        "                izlazni_podfolder = os.path.join(izlazni_buka_folder, item)\n",
        "                os.makedirs(izlazni_podfolder, exist_ok=True)\n",
        "\n",
        "                # Obrada fajlova u podfolderu\n",
        "                for filename in os.listdir(item_path):\n",
        "                    ulazni_fajl = os.path.join(item_path, filename)\n",
        "                    izlazni_fajl = os.path.join(izlazni_podfolder, filename)\n",
        "\n",
        "                    if filename.endswith('.json'):\n",
        "                        print(f\"  Obrada JSON: {filename}\")\n",
        "                        if procesiraj_json_metrike(ulazni_fajl, izlazni_fajl):\n",
        "                            processed_files += 1\n",
        "                        else:\n",
        "                            errors += 1\n",
        "\n",
        "                    elif filename.endswith('.csv'):\n",
        "                        print(f\"  Obrada CSV: {filename}\")\n",
        "                        if procesiraj_csv_metrike(ulazni_fajl, izlazni_fajl):\n",
        "                            processed_files += 1\n",
        "                        else:\n",
        "                            errors += 1\n",
        "\n",
        "            elif os.path.isfile(item_path):\n",
        "                # Ako su fajlovi direktno u buka.ba folderu\n",
        "                filename = item\n",
        "                ulazni_fajl = item_path\n",
        "                izlazni_fajl = os.path.join(izlazni_buka_folder, filename)\n",
        "\n",
        "                if filename.endswith('.json'):\n",
        "                    print(f\"Obrada JSON: {filename}\")\n",
        "                    if procesiraj_json_metrike(ulazni_fajl, izlazni_fajl):\n",
        "                        processed_files += 1\n",
        "                    else:\n",
        "                        errors += 1\n",
        "\n",
        "                elif filename.endswith('.csv'):\n",
        "                    print(f\"Obrada CSV: {filename}\")\n",
        "                    if procesiraj_csv_metrike(ulazni_fajl, izlazni_fajl):\n",
        "                        processed_files += 1\n",
        "                    else:\n",
        "                        errors += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Globalna greška pri obradi: {e}\")\n",
        "\n",
        "    return processed_files, errors\n",
        "\n",
        "# Glavni program\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"FAZA 3: IZRAČUNAVANJE EVALUACIJSKIH METRIKA\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Pronalaženje ispravne putanje do ulaznih fajlova (iz Faze 2)\n",
        "    INPUT_FOLDER = find_correct_path(\"[F2]SumarizovaniTekstovi\")\n",
        "    OUTPUT_FOLDER = os.path.join('/content/drive/MyDrive', \"[F3]EvaluacijaTekstova\")\n",
        "\n",
        "    print(f\"Ulazni folder: {INPUT_FOLDER}\")\n",
        "    print(f\"Izlazni folder: {OUTPUT_FOLDER}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Kreiranje izlaznog foldera\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    print(f\"Kreiran izlazni folder: {OUTPUT_FOLDER}\")\n",
        "\n",
        "    # Obrada svih fajlova\n",
        "    processed, errors = obradi_sve_fajlove(INPUT_FOLDER, OUTPUT_FOLDER)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(f\"Obrada završena!\")\n",
        "    print(f\"Uspješno obrađeno: {processed} fajlova\")\n",
        "    print(f\"Greške: {errors}\")\n",
        "    print(f\"Rezultati su sačuvani u folderu: {OUTPUT_FOLDER}\")\n",
        "    print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzItIMkVGHYZ",
        "outputId": "8e4c7432-ca54-400f-ec3b-44cc665728ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "==================================================\n",
            "FAZA 3: IZRAČUNAVANJE EVALUACIJSKIH METRIKA\n",
            "==================================================\n",
            "Tražim ispravnu putanju za [F2]SumarizovaniTekstovi...\n",
            "Provjeravam: /content/drive/MyDrive/[F2]SumarizovaniTekstovi\n",
            "Pronađena putanja: /content/drive/MyDrive/[F2]SumarizovaniTekstovi\n",
            "Ulazni folder: /content/drive/MyDrive/[F2]SumarizovaniTekstovi\n",
            "Izlazni folder: /content/drive/MyDrive/[F3]EvaluacijaTekstova\n",
            "==================================================\n",
            "Kreiran izlazni folder: /content/drive/MyDrive/[F3]EvaluacijaTekstova\n",
            "Obrađujem fajlove iz /content/drive/MyDrive/[F2]SumarizovaniTekstovi/buka.ba...\n",
            "Obrada direktorija: Sport\n",
            "  Obrada JSON: SportSviClanci.json\n",
            "  Obrada CSV: SportSviClanci.csv\n",
            "Obrada direktorija: TV\n",
            "  Obrada JSON: TVSviClanci.json\n",
            "  Obrada CSV: TVSviClanci.csv\n",
            "Obrada direktorija: Region\n",
            "  Obrada CSV: RegionSviClanciTreciDio.csv\n",
            "  Obrada CSV: RegionSviClanciPrviDio.csv\n",
            "  Obrada JSON: RegionSviClanciDrugiDio.json\n",
            "  Obrada JSON: RegionSviClanciPrviDio.json\n",
            "  Obrada CSV: RegionSviClanciDrugiDio.csv\n",
            "  Obrada JSON: RegionSviClanciTreciDio.json\n",
            "Obrada direktorija: Kolumne\n",
            "  Obrada CSV: KolumneSviClanci.csv\n",
            "  Obrada JSON: KolumneSviClanci.json\n",
            "Obrada direktorija: Kultura i zabava\n",
            "  Obrada JSON: KulturaIZabavaSviClanciPrviDio.json\n",
            "  Obrada JSON: KulturaIZabavaSviClanciDrugiDio.json\n",
            "  Obrada JSON: KulturaIZabavaSviClanciCetvrtiDio.json\n",
            "  Obrada CSV: KulturaIZabavaSviClanciPetiDio.csv\n",
            "  Obrada CSV: KulturaIZabavaSviClanciPrviDio.csv\n",
            "  Obrada JSON: KulturaIZabavaSviClanciPetiDio.json\n",
            "  Obrada CSV: KulturaIZabavaSviClanciCetvrtiDio.csv\n",
            "  Obrada CSV: KulturaIZabavaSviClanciTreciDio.csv\n",
            "  Obrada JSON: KulturaIZabavaSviClanciTreciDio.json\n",
            "  Obrada CSV: KulturaIZabavaSviClanciDrugiDio.csv\n",
            "Obrada direktorija: Ekonomija\n",
            "  Obrada CSV: EkonomijaSviClanciPrviDio.csv\n",
            "  Obrada JSON: EkonomijaSviClanciPrviDio.json\n",
            "  Obrada CSV: EkonomijaSviClanciDrugiDio.csv\n",
            "  Obrada JSON: EkonomijaSviClanciDrugiDio.json\n",
            "Obrada direktorija: Karikature i stripovi\n",
            "  Obrada JSON: KarikatureIStripoviSviClanci.json\n",
            "  Obrada CSV: KarikatureIStripoviSviClanci.csv\n",
            "Obrada direktorija: Podcast\n",
            "  Obrada JSON: PodcastSviClanci.json\n",
            "  Obrada CSV: PodcastSviClanci.csv\n",
            "Obrada direktorija: Intervju\n",
            "  Obrada JSON: IntervjuSviClanci.json\n",
            "  Obrada CSV: IntervjuSviClanci.csv\n",
            "Obrada direktorija: BiH\n",
            "  Obrada JSON: BiHSviClanciTreciDio.json\n",
            "  Obrada JSON: BiHSviClanciOsmiDio.json\n",
            "  Obrada JSON: BiHSviClanciSestiDio.json\n",
            "  Obrada CSV: BiHSviClanciSestiDio.csv\n",
            "  Obrada JSON: BiHSviClanciDrugiDio.json\n",
            "  Obrada CSV: BiHSviClanciTreciDio.csv\n",
            "  Obrada CSV: BiHSviClanciSedmiDio.csv\n",
            "  Obrada JSON: BiHSviClanciPetiDio.json\n",
            "  Obrada CSV: BiHSviClanciDrugiDio.csv\n",
            "  Obrada JSON: BiHSviClanciPrviDio.json\n",
            "  Obrada CSV: BiHSviClanciCetvrtiDio.csv\n",
            "  Obrada CSV: BiHSviClanciPrviDio.csv\n",
            "  Obrada JSON: BiHSviClanciSedmiDio.json\n",
            "  Obrada CSV: BiHSviClanciOsmiDio.csv\n",
            "  Obrada CSV: BiHSviClanciPetiDio.csv\n",
            "  Obrada JSON: BiHSviClanciCetvrtiDio.json\n",
            "Obrada direktorija: Svijet\n",
            "  Obrada CSV: SvijetSviClanciPrviDio.csv\n",
            "  Obrada JSON: SvijetSviClanciDrugiDio.json\n",
            "  Obrada JSON: SvijetSviClanciCetvrtiDio.json\n",
            "  Obrada CSV: SvijetSviClanciDrugiDio.csv\n",
            "  Obrada CSV: SvijetSviClanciCetvrtiDio.csv\n",
            "  Obrada JSON: SvijetSviClanciTreciDio.json\n",
            "  Obrada JSON: SvijetSviClanciPrviDio.json\n",
            "  Obrada CSV: SvijetSviClanciTreciDio.csv\n",
            "\n",
            "==================================================\n",
            "Obrada završena!\n",
            "Uspješno obrađeno: 56 fajlova\n",
            "Greške: 0\n",
            "Rezultati su sačuvani u folderu: /content/drive/MyDrive/[F3]EvaluacijaTekstova\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zipovanje i instaliranje foldera\n",
        "# Kreiranje fajla /content/eval_zip.zip\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive(\n",
        "    base_name=\"/content/eval_zip\",  # izlazni zip bez ekstenzije\n",
        "    format=\"zip\",\n",
        "    root_dir=\"/content/drive/MyDrive/[F3]EvaluacijaTekstova\"  # ulazni folder\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U3lfQ4ObOuQ8",
        "outputId": "767be8bb-6f34-41df-af31-75c0f5abe4bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/eval_zip.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preuzimanje zipa\n",
        "from google.colab import files\n",
        "\n",
        "files.download(\"/content/eval_zip.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "myJqk0FIPFjo",
        "outputId": "17ab23dd-a247-4967-8134-ecbcdb5926cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_01ebf5d1-6cdc-4118-9d50-fe97a08073de\", \"eval_zip.zip\", 522049433)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}